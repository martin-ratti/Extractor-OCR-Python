"""
M√≥dulo de infraestructura que implementa el servicio de OCR
con detecci√≥n de color de resaltador para m√∫ltiples colores.
"""
import cv2
import numpy as np
import pytesseract
import os
from typing import Protocol, Dict, Tuple

# --- Tipos de Datos ---
ColorRange = Dict[str, Tuple[np.ndarray, np.ndarray]]

# --- Protocolo ---
class OcrServiceProtocol(Protocol):
    """Define el contrato que cualquier servicio de OCR debe cumplir."""
    def extract_text_from_image(self, image_path: str, color: str) -> str:
        ...


# --- Implementaci√≥n Concreta ---
class OcrService:
    """
    Servicio OCR que detecta texto en zonas resaltadas con color.
    Incluye detecci√≥n autom√°tica del ejecutable de Tesseract.
    """
    DEBUG = False  # Modo de prueba desactivado para producci√≥n

    def __init__(self):
        # Rango HSV de cada color de resaltador
        # HSV: Hue (0-180), Saturation (0-255), Value (0-255)
        # Rangos calibrados basados en an√°lisis de im√°genes reales de documentos
        # Rango HSV de cada color de resaltador
        # HSV: Hue (0-180), Saturation (0-255), Value (0-255)
        # Rangos calibrados para ser EXCLUSIVOS y evitar solapamientos.
        # Saturation Min subido a 50 para ignorar sombras grises y blancos sucios.
        self.color_ranges: ColorRange = {
            # Naranja: 0-18 (Antes 0-25)
            "naranja": (np.array([0, 50, 80]), np.array([18, 255, 255])),
            # Amarillo: 19-35 (Antes 22-45, evitando verde)
            "amarillo": (np.array([19, 50, 120]), np.array([35, 255, 255])),
            # Verde: 36-90 (Antes 35-85, rango principal)
            "verde": (np.array([36, 50, 120]), np.array([90, 255, 255])),
            # Celeste: 91-110
            "celeste": (np.array([91, 50, 120]), np.array([110, 255, 255])),
            # Azul: 111-125
            "azul": (np.array([111, 50, 120]), np.array([125, 255, 255])),
            # Violeta: 126-160
            "violeta": (np.array([126, 50, 120]), np.array([160, 255, 255])),
            # Rosa: 161-180
            "rosa": (np.array([161, 50, 120]), np.array([180, 255, 255])),
        }

        # --- DETECCI√ìN AUTOM√ÅTICA DE TESSERACT ---
        posibles_rutas = [
            r"C:\Program Files\Tesseract-OCR\tesseract.exe",
            r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe",
            os.path.join(os.getcwd(), "Tesseract-OCR", "tesseract.exe"),
            os.path.join(os.path.dirname(__file__), "..", "..", "Tesseract-OCR", "tesseract.exe"),
        ]

        for ruta in posibles_rutas:
            ruta_absoluta = os.path.abspath(ruta)
            if os.path.exists(ruta_absoluta):
                pytesseract.pytesseract.tesseract_cmd = ruta_absoluta
                print(f"‚úÖ Tesseract encontrado en: {ruta_absoluta}")
                break
        else:
            print("‚ö†Ô∏è No se encontr√≥ Tesseract. Coloca la carpeta 'Tesseract-OCR' junto al .exe o inst√°lalo en Windows.")

    def correct_orientation(self, image: np.ndarray) -> np.ndarray:
        """
        Detecta la orientaci√≥n de la imagen y la rota si es necesario.
        """
        try:
            # Usamos Tesseract OSD (Orientation and Script Detection)
            # image_to_osd devuelve info como: "Rotate: 90\nOrientation in degrees: 90\n..."
            osd_data = pytesseract.image_to_osd(image)
            
            rotation_angle = 0
            # Parsear la salida texto de OSD
            for line in osd_data.splitlines():
                if "Rotate:" in line:
                    rotation_angle = int(line.split(":")[1].strip())
                    break
            
            if rotation_angle == 0:
                return image

            print(f"üîÑ Auto-rotaci√≥n detectada: {rotation_angle}¬∞")

            # Rotar la imagen seg√∫n el √°ngulo detectado
            if rotation_angle == 90:
                image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
            elif rotation_angle == 180:
                image = cv2.rotate(image, cv2.ROTATE_180)
            elif rotation_angle == 270:
                image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)
            
            return image

        except Exception as e:
            # Si falla OSD (ej. imagen sin suficiente texto para detectar orientaci√≥n),
            # devolvemos la original sin cambios.
            # print(f"Info: No se pudo detectar orientaci√≥n ({e})")
            return image

    def detect_active_colors(self, image: np.ndarray) -> list[str]:
        """
        Analiza la imagen para determinar qu√© colores de resaltado est√°n presentes.
        Usa un umbral din√°mico basado en el tama√±o de la imagen y un umbral relativo
        para filtrar falsos positivos (ruido).
        """
        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        height, width, _ = image.shape
        total_pixels = height * width
        
        # Umbral 1: √Årea m√≠nima absoluta (0.2% de la imagen)
        # Para una foto de 12MP (4000x3000), esto es ~24,000 p√≠xeles.
        # Para 720p (1280x720), esto es ~1,800 p√≠xeles.
        MIN_AREA_PERCENT = 0.002 
        min_pixels_absolute = int(total_pixels * MIN_AREA_PERCENT) # Aumentamos umbral significativamente

        detected_stats = {}

        for color_name, (lower, upper) in self.color_ranges.items():
            mask = cv2.inRange(hsv_image, lower, upper)
            
            # Dilatar m√°scara para conectar puntos dispersos antes de contar
            # Revertido a solo dilataci√≥n simple para no perder detalles finos
            kernel = np.ones((5,5), np.uint8)
            # mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel) # ELIMINADO: Com√≠a demasiado texto
            mask = cv2.dilate(mask, kernel, iterations=2)

            count = cv2.countNonZero(mask)
            
            if count > min_pixels_absolute:
                detected_stats[color_name] = count
        
        if not detected_stats:
            return []

        # Umbral 2: Relativo al color dominante
        # Si el verde tiene 100,000 px y el violeta (sombra) tiene 5,000, ignoramos el violeta.
        max_pixels = max(detected_stats.values())
        RELATIVE_THRESHOLD = 0.20 # Debe tener al menos el 20% de p√≠xeles del color dominante
        
        final_colors = []
        for color, count in detected_stats.items():
            if count >= max_pixels * RELATIVE_THRESHOLD:
                final_colors.append(color)
            elif self.DEBUG:
                print(f"‚ö†Ô∏è Color '{color}' descartado por ser minoritario ({count} px vs {max_pixels} px)")

        return final_colors

    def extract_text_from_image(self, image_path: str, color: str = "auto") -> str:
        """
        M√©todo √öNICO de extracci√≥n inteligente.
        1. Intenta detectar colores de resaltado.
        2. Si encuentra colores, extrae el texto de esas zonas.
        3. Si NO encuentra colores, escanea toda la p√°gina con estrategia robusta (Smart Fallback).
        """
        try:
            image = cv2.imread(image_path)
            if image is None:
                return "Error: No se pudo cargar la imagen."

            # --- Corregir orientaci√≥n ---
            image = self.correct_orientation(image)
            # ---------------------------

            # Paso 1: Intentar detecci√≥n de colores (Modo Resaltador)
            active_colors = self.detect_active_colors(image)
            
            if active_colors:
                text_from_colors = self._extract_highlighted_text(image, active_colors)
                if text_from_colors:
                    return text_from_colors
                # Si detect√≥ colores pero no pudo leer texto, caer al fallback
                if self.DEBUG: print("‚ö†Ô∏è Colores detectados pero sin texto legible. Intentando escaneo completo...")

            # Paso 2: Fallback a Escaneo Completo (Modo "Sin Filtro" Robusto)
            return self._extract_full_page_robust(image)

        except Exception as e:
            return f"Ocurri√≥ un error considerable durante el OCR: {e}"

    def _extract_highlighted_text(self, image: np.ndarray, active_colors: list) -> str:
        """Extrae texto solo de las zonas de los colores especificados."""
        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        _, thresh_image = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY_INV)
        
        kernel_connect = np.ones((3, 15), np.uint8) # Para conectar letras horizontalmente
        kernel_clean = np.ones((5, 5), np.uint8)    # Para eliminar ruido

        config = '-l spa+eng --psm 6'

        final_output = []
        for color_name in active_colors:
            lower, upper = self.color_ranges[color_name]
            mask = cv2.inRange(hsv_image, lower, upper)
            
            # 1. Limpieza de ruido ELIMINADA para recuperar calidad de texto
            # cleaned_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_clean)
            
            # 2. Solo Dilataci√≥n para cubrir letras (usamos la mask original)
            dilated_mask = cv2.dilate(mask, kernel_connect, iterations=3)
            
            final_image_part = cv2.bitwise_and(thresh_image, thresh_image, mask=dilated_mask)
            
            text_part = pytesseract.image_to_string(final_image_part, config=config).strip()
            
            # Filtrar basura muy corta (menos de 3 letras suele ser ruido)
            if text_part and len(text_part) > 3:
                header = f"{color_name.upper()}:"
                final_output.append(f"{header}\n\n{text_part}")
        
        if final_output:
            return "\n\n" + ("-"*30) + "\n\n".join(final_output)
        return ""

    def _extract_full_page_robust(self, image: np.ndarray) -> str:
        """Intenta leer la p√°gina completa usando m√∫ltiples estrategias de pre-procesamiento."""
        configs_to_try = [
            # Intento 1: Pre-procesamiento AVANZADO (Mejor para sombras/curvatura)
            ("Avanzado", lambda img: self._preprocess_advanced(img), '-l spa+eng --psm 3'),
            # Intento 2: Pre-procesamiento M√çNIMO (Mejor para luz uniforme)
            ("M√≠nimo", lambda img: self._preprocess_minimal(img), '-l spa+eng --psm 3'),
            # Intento 3: Raw (Sin tocar)
            ("Raw", lambda img: img, '-l spa+eng --psm 3'),
             # Intento 4: PSM 6 Fallback
            ("Bloque", lambda img: self._preprocess_minimal(img), '-l spa+eng --psm 6')
        ]

        for name, preprocess_func, cfg in configs_to_try:
            try:
                processed_img = preprocess_func(image)
                text = pytesseract.image_to_string(processed_img, config=cfg).strip()
                if len(text) > 15: # Umbral m√≠nimo de √©xito
                    if self.DEBUG: print(f"‚úÖ √âxito con estrategia: {name}")
                    return text
            except Exception as e:
                if self.DEBUG: print(f"‚ö†Ô∏è Fall√≥ estrategia {name}: {e}")
                continue
        
        return "No se encontr√≥ texto legible en la imagen (Intento fallido en todos los modos)."

    def _preprocess_advanced(self, image):
        """CLAHE + Denoise + Adaptive Threshold"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        denoised = cv2.fastNlMeansDenoising(enhanced, None, 10, 7, 21)
        binary = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        return binary

    def _preprocess_minimal(self, image):
        """Grayscale + Slight Blur"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        return cv2.GaussianBlur(gray, (3, 3), 0)


